# ASMUS Workshop '23

<div align=center>
 <img src="im/asmus.png" height=150px>
</div>

**The 4th International Workshop of Advances in Simplifying Medical UltraSound (ASMUS) - a workshop held in conjunction with [MICCAI 2023](https://conferences.miccai.org/2023/), the 26th International Conference on Medical Image Computing and Computer Assisted Intervention.**

**ASMUS is the offical workshop of the [MICCAI Special Interest Group on Medical Ultrasound](home).**

> **The ASMUS Workshop is schedule to be held on October 8th. Stay tuned for a detailed program!**

> Proceedings of the 4th International Workshop of Advances in Simplifying Medical Ultrasound (ASMUS) will be available free of charge for ASMUS participants after the events.

## Call for Papers

Papers will consist of maximum 8 pages (text, figures and tables) + up to 2 pages for references only. They are to be submitted electronically in [Springer LNCS (Lecture Notes in Computer Science) style](https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines) and are subject to double blind review. Information on submission to follow.

The papers will be evaluated by external reviewers and our organizing committee for inclusion in the workshop as a presentation (oral or poster). Accepted full-length manuscripts will be published with Springer LNCS and the best papers will be selected for industry-sponsored awards. Original research contributions are invited. Proof-of-concept research from novel research directions is also encouraged.

One of the popular features of ASMUS, live demonstrations, will return for ASMUS 2023. Capitalising on the unique real-time and portability aspects of ultrasound-based applications, we plan for live demonstrations covering AI, interventional and robotics areas. All accepted papers will be offered the option to present a live demonstration.

You may start the submission process at [Springer Nature EquinOCS](https://equinocs.springernature.com/service/ASMUS2023). E-Mail registration required prior to submission, which can be accessed by clicking the "Submit now" button on the previous link. If you have any issues registering or with the submission process, please contact the PC Chairs via the platform or via E-Mail.



In this exciting era for medical ultrasound, recent developments in deep learning (artificial intelligence) and medical robotics have started to show clinically measurable improvement in assisting ultrasound examinations, ultrasound-guided interventions and surgery. This year, ASMUS is soliciting submissions, including work from the following areas:

### Ultrasound Assisted by Artificial Intelligence and Medical Robotics:
- Ultrasound imaging with robotic (automated) assistance
- Machine learning methods in ultrasound analysis and guidance
- Automated interpretation and measurement for ultrasound
- Ultrasound quality and skills assessment

### Multimodality Ultrasound Imaging:
- Ultrasound with other non-imaging sensory information, e.g. positional and eye tracking
- Ultrasound with another pre-/intra-procedural imaging, e.g. camera videos, CT, MR, fluorescence
- Different modes of ultrasound imaging, e.g. photoacoustic, Doppler, functional ultrasound, tissue quantification

### Applications:
- Global healthcare
- Training sonographers and other users
- Assisting non-expert healthcare professionals
- Point-of-care ultrasound systems and scenarios
- Assisting surgery and interventions
- Streamlining clinical ultrasound workflow
- Sonography data science


| Preliminary Workshop Timeline             |                            |
| ----------------------------- | -------------------------- |
| ~~July 3 2023~~ July 10 2023  | Paper Submission Deadline  |
| July 28 2023 | Reviews Due |
| ~~July 28 2023~~ August 3 2023 | Notification of Acceptance |
| August 18 2023                | Camera Ready Submission    |
| October 8 2023                | ASMUS Workshop             |

All times are in "anywhere on earth". 

## Program

**The half day ASMUS workshop will take place on October 8th 2023, and include live practical technology demonstrations, paper presentations, Q&A sessions, and keynote talks.**

### Preliminary Program

07:50-08:00 Introduction (organisers)
 
08:00 - 09:00 (12 + 3 min): *Segmentation, Predictions, and Automated Assessments*
- paper 1: Zhao, Men, Gleed, Papageorghiou, Noble: Ultrasound Video Segmentation with Adaptive Temporal Memory
- paper 2: Pegios, Pi Fogtmann Sejer, Bashir, Bo Søndergaard Svendsen, Nielsen, Petersen, Nymark Christensen, Tolsgaard, Feragen, Lin: Leveraging Shape and Spatial Information for Spontaneous Preterm Birth Prediction 
- paper 3: Wong, Raheli, Bashir, Svendsen, Tolsgaard, Feragen, Christensen, Lin: An Automatic Guidance and Quality Assessment System for Doppler Imaging of Umbilical Artery
- paper 4: Benjamin, Asokan, Alhosani, Alasmawi, Diehl, Bricker, Nandakumar, Yaqub: Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos

09:00 - 10:00 *Poster lightning talks (5 min)*
- paper l1: Singla, Ringstrom, Hu, Lessoway, Reid, Nguan, Rohlign: The Open Kidney Ultrasound Data Set
- paper l2: Ng, Gao, Mohammed Furqan, Yeo, Lau, Ngiam, Khoo: HoloPOCUS: Mixed Reality 3D Ultrasound Reconstruction and Overlay
- paper l3: Bhattacharya, Vesal, Jahanandish, Choi, Zhou, Kornberg, Sommer, Fan, Brooks, Sonn, Rusu: MIC-CUSP: Multimodal Image Correlations for Ultrasound-based Prostate Cancer Detection
- paper l4: Colussi, Mascetti, Ahmetovic, Civitarese, Cacciatori, Peyvandi, Gualtierotti, Arcudi, Bettini: GAJA - Guided self-Acquisition of Joint ultrAsound images
- paper l5: Li, Shen, Li, Barratt, Dowrick, Clarkson, Vercauteren, Hu: Privileged Anatomical and Protocol Discrimination in Trackerless 3D Ultrasound Reconstruction
- paper l6: Stojanovski, Hermida, Lamata, Beqiri, Gomez: Echo from noise: synthetic ultrasound image generation using diffusion models for real image segmentation
- paper l7: FANG, Delingette, Ayache: Anatomical Landmark Detection for Initializing US and MR Image Registration
- paper l8: Thomas, Tiago , Andreassen, Aase, Sprem, Steen, Solberg, Ben-Yosef: Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach
- paper l9: Zhou, Knight, Felfeliyan, Gosh, Alves-Pereira, Keen, Hareendranathan, Jaremko: Self-supervised learning to more efficiently generate segmentation masks for wrist ultrasound
- paper l10: Adhikari, Dhakal, Thapaliya, Bhandari, Poudel, Khanal: Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography
- paper l11: Gonzalez Duque, Velikova, Navab, Mateus, Zirus: Can ultrasound confidence maps predict sonogaphers labeling variability?

10:00 - 10:30: *coffee break, live demos, and poster session*

*Demos:*
- Connolly, Deguet,  Ungi, Kumar, Lasso, Sunderland, Kazanzides, Krieger, Tokuda, Leonard, Fichtinger, Mousavi, and Taylor: [Haptic feedback and ultrasound guidance for
lumpectomy with SlicerROS2](https://miccai-ultrasound.github.io/files/Connolly_MICCAI_ASMUS_demo_v1.pdf)
- Ultromics: [EchoGo Precision HFpEF detection](https://thinksono.com/)
- ThinkSono: [DVT detection at the front line of care](https://thinksono.com/)
- ImFusion: [ImFusion Suite for Ultrsound image analysis](https://www.imfusion.com/products/imfusion-suite)
 
10:30 - 11:30: *keynote address Prof. Mirabela Rusu*
 
11:30 - 12:30 (12 + 3 min) *Contrastive Learning, and Multi-Task Innovations*
- paper 5: Ravishankar, Annangi, Melapudi, Patil, Patil: SonoSAM - Segment Anything on Ultrasound Images
- paper 6: Prieto, Benabdelkader, Pokaprakarn, Shah, Sebastião, Dan, Almnini, Diaz, Chari, Chi, Stringer, Stringer: SimNorth: A novel contrastive learning approach for clustering prenatal ultrasound images 
- paper 7: Charton, Ren, Kim, Gonzalez, Khambhati, Cheng, DeFrancesco, Waheed, Marciniak, Moura, Cardoso, Lima, Picard, Li, Li: Multi-task Learning for Hierarchically-Structured Images: Study on Echocardiogram View Classification 
- paper 8: Tafuro, Jansen, Išgum: Temporally consistent segmentations from sparsely labeled echocardiograms using image registration for pseudo-labels generation

12:30 - 12:40 *Closing Remarks and Prizes*

lunch at 12:30-13:30

## Keynote Speaker

### Prof. Mirabela Rusu
![Prof. Mirabela Rusu](https://profiles.stanford.edu/proxy/api/cap/profiles/185796/resources/profilephoto/350x350.1513908263182.jpg)

*Title:* Artificial intelligence methods for b-mode ultrasound of the prostate to guide the biopsy procedure: Are we there yet? 

*Abstract:* Despite the advancements in prostate MRI, most prostate biopsies are still performed under the guidance of ultrasound alone. These procedures are imperfect, missing >50% of clinically significant cancers. By comparison, when MRI is utilized in an MRI-Ultrasound guided biopsy, the procedure only misses 12% of cancers. My team’s research has been focusing on using the ubiquitous but noisy b-mode ultrasound images to detect and localize prostate cancer, in approaches that often rely on MRI during the training of the models, but only use b-mode ultrasound images at inference time in new patients. Improving the ability of ultrasound to better show cancer has potential to enable early cancer detection, sparing men of biopsies when they are not needed, and allow for better targeting during local treatment. 

*Bio:* Dr. Mirabela Rusu received her MS and PhD in Computational Biomedicine from University of Texas, Houston, and focused her research on the fusion of biomolecular structural data from different sources (i.e., cryo-electron microscopy and X-ray crystallography). Her postdoctoral training at Rutgers and Case Western Reserve University was focused on developing computational methods for the fusion of medical images, i.e., to register radiology or pathology images, or create population atlases for prostate cancer studies. Following postdoctoral training, Dr. Rusu joined Industry as an Image Analysis Scientist/Lead Engineer. Currently, Dr. Rusu is an Assistant Professor of Radiology, and by courtesy, Urology and Data Science, at Stanford University, where she leads the Personalized Integrative Medicine Laboratory (http://pimed.stanford.edu). Dr. Rusu’s team focuses on developing analytic methods to improve the interpretation of radiology images by taking advantage of existing high-resolution information during training but only needing lower resolution radiology images during inference (e.g., when applied in new patients).  


## Organizers
### Chairs
* Bernhard Kainz (Co-Chair, FAU Erlangen-Nürnberg, DE, and Imperial College London, UK)
* Julia Schnabel (Co-Chair, Technical University of Munich, DE)
* Bishesh Khanal (outreach Co-Chair, NAAMII, Nepal)

### Organising Committee
* Alison Noble (University of Oxford, UK)
* Stephen Aylward (Kitware, USA)
* Yipeng Hu (University College London, UK)
* Purang Abolmaesumi (University of British Columbia, CA)
* Dong Ni (Shenzhen University, CN)
* Emad Boctor (Johns Hopkins University, USA)
* Andy King (King’s College London, UK)
* Ana Namburete (University of Oxford, UK)
* Thomas van den Heuvel (Radboud University, NL)
* Wolfgang Wein (ImFusion, DE)
* Parvin Mousavi (Queen’s University, CA)
* Alberto Gomez (King’s College London and Ultromics, UK)
* Veronika Zimmer (Technical University of Munich, DE)

### Delivery Team
* Thomas Day (King’s College London, UK)
* Mischa Dombrowski (FAU Erlangen-Nürnberg)
* Johanna Mueller (FAU Erlangen-Nürnberg)
* Matthew Baugh (Imperial College London)
* Zachary Baum (University College London)

### Advisory Board

* Gabor Fichtinger (Queen’s University, Canada)
* Kawal Rhode (King’s College London, UK)
* Russ Taylor (Johns Hopkins University, USA)
* Chris de Korte (Radboud University Nijmegen, Netherlands)
* Nassir Navab (Technical University of Munich, Germany)
* Reza Razavi (King’s College London, UK)
* Joseph V. Hajnal (King’s College London, UK)
